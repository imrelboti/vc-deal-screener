# scheduler/auto_collector.py
"""
Automated Collection Scheduler
===============================
Planifie et ex√©cute les collectes automatiques de donn√©es
"""

import asyncio
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from datetime import datetime
import logging
import sys
import os

# Ajouter le parent directory au path
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from main_orchestrator import DataCollectionOrchestrator

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class AutoCollectionScheduler:
    """
    Scheduler pour collectes automatiques
    
    Schedules configur√©s:
    - Collecte compl√®te: Dimanche √† 3h du matin (hebdomadaire)
    - Collecte incr√©mentale: Tous les jours √† 2h du matin
    - Actualisation rapide: Toutes les 6 heures (news, updates)
    """
    
    def __init__(self):
        self.scheduler = AsyncIOScheduler()
        self.orchestrator = None
        self.is_running = False
    
    async def initialize(self):
        """Initialize l'orchestrateur"""
        logger.info("üöÄ Initialisation du scheduler automatique...")
        self.orchestrator = DataCollectionOrchestrator()
        await self.orchestrator.initialize()
        logger.info("‚úÖ Scheduler initialis√©")
    
    def setup_schedules(self):
        """Configure les plannings de collecte"""
        
        # Collecte compl√®te hebdomadaire (Dimanche 3h)
        self.scheduler.add_job(
            self.run_full_collection,
            trigger=CronTrigger(day_of_week='sun', hour=3, minute=0),
            id='full_collection_weekly',
            name='Collecte Compl√®te Hebdomadaire',
            replace_existing=True
        )
        logger.info("üìÖ Collecte compl√®te programm√©e: Dimanche 3h00")
        
        # Collecte incr√©mentale quotidienne (2h)
        self.scheduler.add_job(
            self.run_incremental_collection,
            trigger=CronTrigger(hour=2, minute=0),
            id='incremental_daily',
            name='Collecte Incr√©mentale Quotidienne',
            replace_existing=True
        )
        logger.info("üìÖ Collecte incr√©mentale programm√©e: Tous les jours 2h00")
        
        # Actualisation rapide (toutes les 6h)
        self.scheduler.add_job(
            self.run_quick_update,
            trigger=CronTrigger(hour='*/6'),
            id='quick_update',
            name='Actualisation Rapide',
            replace_existing=True
        )
        logger.info("üìÖ Actualisation rapide programm√©e: Toutes les 6h")
        
        # Nettoyage base de donn√©es (Samedi 1h)
        self.scheduler.add_job(
            self.run_database_cleanup,
            trigger=CronTrigger(day_of_week='sat', hour=1, minute=0),
            id='db_cleanup_weekly',
            name='Nettoyage Base de Donn√©es',
            replace_existing=True
        )
        logger.info("üìÖ Nettoyage DB programm√©: Samedi 1h00")
    
    async def run_full_collection(self):
        """Ex√©cute une collecte compl√®te"""
        logger.info("=" * 80)
        logger.info("üîÑ COLLECTE COMPL√àTE D√âMARR√âE")
        logger.info("=" * 80)
        
        try:
            await self.orchestrator.run_full_collection()
            logger.info("‚úÖ Collecte compl√®te termin√©e avec succ√®s")
        except Exception as e:
            logger.error(f"‚ùå Erreur collecte compl√®te: {e}", exc_info=True)
    
    async def run_incremental_collection(self):
        """Ex√©cute une collecte incr√©mentale (mise √† jour)"""
        logger.info("üîÑ Collecte incr√©mentale d√©marr√©e...")
        
        try:
            # Collecte uniquement depuis sources rapides
            from collectors.google_search_collector import GoogleSearchCollector
            from collectors.local_sources_collector import LocalSourcesCollector
            
            collectors = [
                GoogleSearchCollector(),
                LocalSourcesCollector()
            ]
            
            all_startups = []
            for collector in collectors:
                try:
                    startups = await collector.collect()
                    all_startups.extend(startups)
                except Exception as e:
                    logger.error(f"Erreur {collector.__class__.__name__}: {e}")
            
            # Processus de nettoyage et sauvegarde
            from utils.data_cleaner import DataCleaner
            
            cleaner = DataCleaner()
            cleaned = await cleaner.process(all_startups)
            
            # Sauvegarder
            for startup in cleaned:
                exists = await self.orchestrator.database.startup_exists(startup['name'])
                if exists:
                    await self.orchestrator.database.update_startup(startup)
                else:
                    await self.orchestrator.database.create_startup(startup)
            
            logger.info(f"‚úÖ Collecte incr√©mentale: {len(cleaned)} startups trait√©es")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur collecte incr√©mentale: {e}", exc_info=True)
    
    async def run_quick_update(self):
        """Actualisation rapide (news, updates)"""
        logger.info("‚ö° Actualisation rapide...")
        
        try:
            # Collecter uniquement les news/updates
            # Implementation simplifi√©e
            logger.info("‚úÖ Actualisation rapide termin√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur actualisation: {e}")
    
    async def run_database_cleanup(self):
        """Nettoyage et optimisation de la base de donn√©es"""
        logger.info("üßπ Nettoyage base de donn√©es...")
        
        try:
            async with self.orchestrator.database.pool.acquire() as conn:
                # Supprimer les doublons
                await conn.execute("""
                    DELETE FROM startups a USING startups b
                    WHERE a.id > b.id AND a.name = b.name
                """)
                
                # Vacuum (PostgreSQL optimization)
                # Note: N√©cessite connexion autocommit
                
                logger.info("‚úÖ Nettoyage termin√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur nettoyage: {e}")
    
    def start(self):
        """D√©marre le scheduler"""
        logger.info("=" * 80)
        logger.info("ü§ñ D√âMARRAGE DU SCHEDULER AUTOMATIQUE")
        logger.info("=" * 80)
        
        self.scheduler.start()
        self.is_running = True
        
        # Afficher les jobs programm√©s
        jobs = self.scheduler.get_jobs()
        logger.info(f"üìã {len(jobs)} t√¢ches programm√©es:")
        for job in jobs:
            logger.info(f"  - {job.name}: {job.next_run_time}")
        
        logger.info("=" * 80)
        logger.info("‚úÖ Scheduler actif - En attente des t√¢ches programm√©es...")
        logger.info("=" * 80)
    
    def stop(self):
        """Arr√™te le scheduler"""
        if self.is_running:
            logger.info("üõë Arr√™t du scheduler...")
            self.scheduler.shutdown()
            self.is_running = False
            logger.info("‚úÖ Scheduler arr√™t√©")


async def main():
    """Point d'entr√©e principal"""
    scheduler = AutoCollectionScheduler()
    
    try:
        # Initialiser
        await scheduler.initialize()
        
        # Configurer les plannings
        scheduler.setup_schedules()
        
        # D√©marrer
        scheduler.start()
        
        # Option: Ex√©cuter une collecte imm√©diate au d√©marrage
        import sys
        if '--run-now' in sys.argv:
            logger.info("üöÄ Ex√©cution imm√©diate d'une collecte compl√®te...")
            await scheduler.run_full_collection()
        
        # Garder le programme en vie
        try:
            while True:
                await asyncio.sleep(60)  # Check toutes les minutes
        except (KeyboardInterrupt, SystemExit):
            logger.info("‚ö†Ô∏è  Interruption d√©tect√©e")
    
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}", exc_info=True)
    
    finally:
        scheduler.stop()
        if scheduler.orchestrator and scheduler.orchestrator.database:
            await scheduler.orchestrator.database.disconnect()


if __name__ == "__main__":
    """
    Usage:
        python scheduler/auto_collector.py              # Mode scheduler
        python scheduler/auto_collector.py --run-now    # + collecte imm√©diate
    """
    asyncio.run(main())
